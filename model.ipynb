{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dd6ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached roboflow-1.2.1-py3-none-any.whl (86 kB)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Collecting numpy>=1.18.5\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Collecting pillow-heif<2\n",
      "  Using cached pillow_heif-1.0.0-cp39-cp39-win_amd64.whl (5.3 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: six in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Collecting urllib3>=1.26.6\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting opencv-python-headless==4.10.0.84\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting Pillow>=7.1.2\n",
      "  Using cached pillow-11.3.0-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting requests-toolbelt\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Collecting idna==3.7\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting pillow-avif-plugin<2\n",
      "  Using cached pillow_avif_plugin-1.5.2-cp39-cp39-win_amd64.whl (9.9 MB)\n",
      "Requirement already satisfied: python-dateutil in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting cycler\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: colorama in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.59.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.23.0)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, urllib3, tqdm, PyYAML, python-dotenv, pyparsing, Pillow, numpy, kiwisolver, importlib-resources, idna, fonttools, cycler, charset_normalizer, certifi, requests, pillow-heif, opencv-python-headless, contourpy, requests-toolbelt, matplotlib, roboflow\n",
      "Successfully installed Pillow-11.3.0 PyYAML-6.0.2 certifi-2025.7.14 charset_normalizer-3.4.2 contourpy-1.3.0 cycler-0.12.1 filetype-1.2.0 fonttools-4.59.0 idna-3.7 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 numpy-2.0.2 opencv-python-headless-4.10.0.84 pillow-avif-plugin-1.5.2 pillow-heif-1.0.0 pyparsing-3.2.3 python-dotenv-1.1.1 requests-2.32.4 requests-toolbelt-1.0.0 roboflow-1.2.1 tqdm-4.67.1 urllib3-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'D:\\v-intership part\\Blood\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in blood-postion-1 to folder:: 100%|██████████| 2548/2548 [00:02<00:00, 1084.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to blood-postion-1 in folder:: 100%|██████████| 99/99 [00:00<00:00, 1119.73it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"GYyB5SrSjvJ2EZsyJgCl\")\n",
    "project = rf.workspace(\"yolo-boyoh\").project(\"blood-postion-t936i\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"folder\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106c42c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Using cached h5py-3.14.0-cp39-cp39-win_amd64.whl (2.9 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.73.1-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: packaging in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-5.29.5-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Requirement already satisfied: setuptools in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Using cached ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.16.0-cp39-cp39-win_amd64.whl (300 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.7.0)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.23.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, h5py, grpcio, google-pasta, gast, absl-py, werkzeug, markdown-it-py, markdown, astunparse, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'd:\\v-intership part\\Blood\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3707594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f632e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = dataset.location\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5cb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe33b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7498af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78 images belonging to 3 classes.\n",
      "Found 4 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory(train_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_gen = val_datagen.flow_from_directory(val_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3a50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False  # freeze base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061a4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482dd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d48de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'd:\\v-intership part\\Blood\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in d:\\v-intership part\\blood\\myenv\\lib\\site-packages (from scipy) (2.0.2)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n",
      "Epoch 1/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7436 - loss: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.7660 - loss: 0.7903 - val_accuracy: 0.7500 - val_loss: 0.9023\n",
      "Epoch 2/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9493 - loss: 0.1401 - val_accuracy: 0.7500 - val_loss: 0.4052\n",
      "Epoch 3/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 929ms/step - accuracy: 0.9819 - loss: 0.0446 - val_accuracy: 1.0000 - val_loss: 0.0956\n",
      "Epoch 4/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
      "Epoch 5/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "Epoch 6/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 7/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 967ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 8/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 933ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 9/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 914ms/step - accuracy: 1.0000 - loss: 7.4078e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 11/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 6.0545e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 12/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 6.2419e-04 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 13/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.0403e-04 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 14/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.3194e-04 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 15/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5792e-04 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 16/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1967e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 17/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3342e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 18/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0528e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 19/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4200e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 20/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 958ms/step - accuracy: 1.0000 - loss: 1.7750e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 21/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 1.5611e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 22/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 938ms/step - accuracy: 1.0000 - loss: 9.3514e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 23/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8126e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 24/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5712e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 25/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.5207e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 26/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8053e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 27/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5607e-04 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 28/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 950ms/step - accuracy: 1.0000 - loss: 8.1248e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 29/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9646e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 30/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 9.0358e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 31/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 942ms/step - accuracy: 1.0000 - loss: 6.8945e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 32/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 919ms/step - accuracy: 1.0000 - loss: 6.7972e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 33/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0073e-04 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 34/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6374e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 35/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 1.5332e-04 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 36/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.9072e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 37/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 949ms/step - accuracy: 1.0000 - loss: 5.3746e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 38/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.2593e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 39/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.9891e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 40/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.8618e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 41/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.4722e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 42/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.5600e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 43/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6272e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 44/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0820e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 45/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.1284e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 46/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 864ms/step - accuracy: 1.0000 - loss: 4.3068e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 47/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 869ms/step - accuracy: 1.0000 - loss: 5.2447e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 48/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 4.0883e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 49/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 985ms/step - accuracy: 1.0000 - loss: 4.7362e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 50/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.0382e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 51/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 951ms/step - accuracy: 1.0000 - loss: 2.9314e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 52/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9180e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 53/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.2827e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 54/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7602e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 55/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6933e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 56/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3281e-04 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 57/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 955ms/step - accuracy: 1.0000 - loss: 3.3663e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 58/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 874ms/step - accuracy: 1.0000 - loss: 5.3889e-05 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 59/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 936ms/step - accuracy: 1.0000 - loss: 2.8733e-05 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 60/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 971ms/step - accuracy: 1.0000 - loss: 4.4053e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 61/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.1516e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 62/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4310e-04 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 63/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7024e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 64/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.6415e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 65/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8691e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 66/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.0017e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 67/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6880e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 68/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9315e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 69/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.2641e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 894ms/step - accuracy: 1.0000 - loss: 2.8573e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6956e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 72/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7631e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 73/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9368e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 74/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4773e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 75/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2359e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 76/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 851ms/step - accuracy: 1.0000 - loss: 3.6566e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 77/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 894ms/step - accuracy: 1.0000 - loss: 2.8580e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 78/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2461e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 79/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 979ms/step - accuracy: 1.0000 - loss: 2.2007e-05 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 80/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4589e-05 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 81/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 871ms/step - accuracy: 1.0000 - loss: 2.7521e-05 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 82/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 2.5013e-05 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 83/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 3.2765e-05 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 84/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 938ms/step - accuracy: 1.0000 - loss: 2.1534e-05 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 85/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 2.5110e-05 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 86/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 919ms/step - accuracy: 1.0000 - loss: 2.3031e-05 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 87/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3540e-05 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 88/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 2.3859e-05 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 89/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 2.1896e-05 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 90/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 2.1281e-05 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 91/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 2.1248e-05 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 92/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 2.7083e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 93/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 907ms/step - accuracy: 1.0000 - loss: 1.9623e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 94/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 872ms/step - accuracy: 1.0000 - loss: 2.3498e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 95/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 968ms/step - accuracy: 1.0000 - loss: 3.3270e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 96/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 897ms/step - accuracy: 1.0000 - loss: 1.4080e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 97/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 934ms/step - accuracy: 1.0000 - loss: 2.2854e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 98/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 938ms/step - accuracy: 1.0000 - loss: 2.1677e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 99/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 2.3900e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 100/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 2.1110e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 101/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 862ms/step - accuracy: 1.0000 - loss: 2.4494e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 102/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7992e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 103/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1260e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 104/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9034e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 105/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 925ms/step - accuracy: 1.0000 - loss: 1.5626e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 106/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 871ms/step - accuracy: 1.0000 - loss: 2.1797e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 107/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 869ms/step - accuracy: 1.0000 - loss: 1.9498e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 108/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 1.7430e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 109/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3626e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 110/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 2.5041e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 111/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 2.0216e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 112/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 1.2885e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 113/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 2.5741e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 114/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 870ms/step - accuracy: 1.0000 - loss: 2.1122e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 115/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 876ms/step - accuracy: 1.0000 - loss: 1.2779e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 116/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4982e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 117/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 1.7475e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 118/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 895ms/step - accuracy: 1.0000 - loss: 2.1561e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 119/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 1.6222e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 120/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 1.9219e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 121/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2012e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 122/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 1.7005e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 123/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 1.5108e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 124/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6099e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 125/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 816ms/step - accuracy: 1.0000 - loss: 1.6654e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 126/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 936ms/step - accuracy: 1.0000 - loss: 1.8741e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 127/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1489e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 128/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 2.0925e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 129/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1176e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 130/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 922ms/step - accuracy: 1.0000 - loss: 2.6421e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 131/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 838ms/step - accuracy: 1.0000 - loss: 1.6766e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 132/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 868ms/step - accuracy: 1.0000 - loss: 1.8456e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 133/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1730e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 134/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 875ms/step - accuracy: 1.0000 - loss: 1.2584e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 135/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 1.8827e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 136/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3800e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 137/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 1.5090e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 138/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4229e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 139/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 841ms/step - accuracy: 1.0000 - loss: 1.7126e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 140/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 861ms/step - accuracy: 1.0000 - loss: 2.1598e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 141/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9675e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 142/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 1.3902e-05 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 143/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7971e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 144/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 1.3644e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 145/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8356e-06 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 146/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 1.6016e-05 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 147/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 1.3351e-05 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 148/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 814ms/step - accuracy: 1.0000 - loss: 1.2710e-05 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 149/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 1.2054e-05 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 150/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3338e-06 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 151/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 895ms/step - accuracy: 1.0000 - loss: 1.3878e-05 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 152/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 1.4908e-05 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 153/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 1.3488e-05 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 154/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2697e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 155/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 935ms/step - accuracy: 1.0000 - loss: 9.0808e-06 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 156/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0349e-05 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 157/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 942ms/step - accuracy: 1.0000 - loss: 7.9144e-06 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 158/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 6.7173e-06 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 159/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 935ms/step - accuracy: 1.0000 - loss: 9.3307e-06 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 160/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.1029e-06 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
      "Epoch 161/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2630e-05 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 162/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 6.2181e-06 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 163/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 835ms/step - accuracy: 1.0000 - loss: 6.3384e-06 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
      "Epoch 164/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 835ms/step - accuracy: 1.0000 - loss: 8.9274e-06 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 165/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7124e-05 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 166/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 7.1968e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 167/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.3695e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 168/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 4.1672e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 169/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 1.0979e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 170/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7123e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 171/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 1.2484e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 172/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 931ms/step - accuracy: 1.0000 - loss: 9.7405e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 173/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 854ms/step - accuracy: 1.0000 - loss: 7.7686e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 174/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 9.9118e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 175/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 1.1631e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 176/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0309e-05 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 177/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 925ms/step - accuracy: 1.0000 - loss: 6.7604e-06 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 178/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 8.7504e-06 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 179/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 990ms/step - accuracy: 1.0000 - loss: 4.8129e-06 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 180/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.5517e-06 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 181/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.7931e-06 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 182/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 8.1290e-06 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 183/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 5.2869e-06 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 184/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0677e-06 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 185/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.7530e-06 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 186/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.1818e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 187/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.5398e-05 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 188/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 902ms/step - accuracy: 1.0000 - loss: 7.1916e-06 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 189/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0625e-05 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 190/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2433e-06 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 191/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.0914e-06 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 192/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 4.9089e-06 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 193/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 7.6168e-06 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 194/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 876ms/step - accuracy: 1.0000 - loss: 5.2166e-06 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 195/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 808ms/step - accuracy: 1.0000 - loss: 7.7307e-06 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 196/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3024e-06 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 197/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 7.5632e-06 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 198/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.7365e-06 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 199/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 9.2924e-06 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 200/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0453e-05 - val_accuracy: 1.0000 - val_loss: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1aabf80da60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install scipy\n",
    "\n",
    "# Train\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b91c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"mobilenetv2_lab_instruments.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9284961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
